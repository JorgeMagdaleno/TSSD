{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0cdd17-61cd-4ca9-80bf-a9433bd1072f",
   "metadata": {},
   "source": [
    "***Práctica 1: Sensado y análisis de audio***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc2ab21-a119-4cbd-b59d-a727feaae9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720bcbca-09f1-4e9a-a113-292cb0391981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43a68b-e97e-48ee-aad1-aee25fb32da7",
   "metadata": {},
   "source": [
    "Funciones para la generacion de audios nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890a15f3-73dc-41a6-9f71-2e691c287f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_silent_wav(filepath, duration_sec=1, sample_rate=44100, channels=1, noise_std=5):\n",
    "    n_samples = int(sample_rate * duration_sec)\n",
    "    \n",
    "    # Generar un silencio con variaciones para simular sonido de ambiente\n",
    "    silence = np.random.normal(loc=0, scale=noise_std, size=n_samples * channels)\n",
    "    silence = silence.astype(np.int16)\n",
    "    \n",
    "    with wave.open(filepath, 'w') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(silence.tobytes())\n",
    "\n",
    "def generate_null_audios(n_files=3, duration=1.0):\n",
    "    base_folder = \"Audios\"\n",
    "    null_folder = os.path.join(base_folder, \"Audios_Null\")\n",
    "    os.makedirs(null_folder, exist_ok=True)\n",
    "    \n",
    "    for i in range(n_files):\n",
    "        for n in range(5):\n",
    "            file_name = f\"null-0{i+1}_0{n+1}.wav\"\n",
    "            file_path = os.path.join(null_folder, file_name)\n",
    "            generate_silent_wav(file_path, duration_sec=duration)\n",
    "            print(f\"Generated: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e5e34-e97c-4d9d-9331-0b22c2321ef9",
   "metadata": {},
   "source": [
    "Cargado de audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac49017-969c-4f37-9837-bdfb0adeca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audios_into_dataframe(root_folder=\"Audios\", valid_extensions=('.wav', '.mp3', '.m4a', '.flac', '.ogg', '.wma', '.aac')):\n",
    "    audio_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith(valid_extensions):\n",
    "                full_path = os.path.join(dirpath, filename)\n",
    "                audio_files.append(full_path)\n",
    "    \n",
    "    data = []\n",
    "    for filepath in audio_files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        label = os.path.basename(os.path.dirname(filepath))\n",
    "        try:\n",
    "            audio_data, sample_rate = librosa.load(filepath, sr=None)\n",
    "            duration = librosa.get_duration(y=audio_data, sr=sample_rate)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filepath}: {e}\")\n",
    "            audio_data, sample_rate, duration = None, None, None\n",
    "        \n",
    "        data.append({\n",
    "            'filepath': filepath,\n",
    "            'filename': filename,\n",
    "            'label': label,\n",
    "            'audio': audio_data,\n",
    "            'sample_rate': sample_rate,\n",
    "            'duration': duration\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1147a0-ef96-4b5b-9744-6549e934c979",
   "metadata": {},
   "source": [
    "Generacion de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4544a01-afdc-4ba8-974e-0d970282d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(audio, noise_factor=0.025):\n",
    "    # Agregar ruido blanco al recording\n",
    "    noise = np.random.randn(len(audio))\n",
    "    return audio + noise_factor * noise\n",
    "\n",
    "def apply_time_stretch(audio, rate=1.2):\n",
    "    # Alangar audio\n",
    "    return librosa.effects.time_stretch(audio, rate=rate)\n",
    "\n",
    "def apply_pitch_shift(audio, sr, n_steps=2):\n",
    "    # Cambiar tono\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def change_volume(audio, factor=1.5):\n",
    "    # Cambiar volumen\n",
    "    return audio * factor\n",
    "\n",
    "def augment_audio(audio, sr):\n",
    "    augmentations = []\n",
    "    \n",
    "    # Original\n",
    "    augmentations.append(('original', audio))\n",
    "    \n",
    "    # Ruido blanco\n",
    "    noise_audio = add_noise(audio, noise_factor=0.025)\n",
    "    augmentations.append(('noise', noise_audio))\n",
    "    \n",
    "    # Audio rapido\n",
    "    ts_audio = apply_time_stretch(audio, rate=1.2)\n",
    "    augmentations.append(('time_stretch_longer', ts_audio))\n",
    "\n",
    "    # Audio lento\n",
    "    ts_audio = apply_time_stretch(audio, rate=0.8)\n",
    "    augmentations.append(('time_stretch_slower', ts_audio))\n",
    "    \n",
    "    # Tono alto\n",
    "    ps_audio = apply_pitch_shift(audio, sr, n_steps=2)\n",
    "    augmentations.append(('pitch_shift_alto', ps_audio))\n",
    "\n",
    "    # Tono bajo\n",
    "    ps_audio = apply_pitch_shift(audio, sr, n_steps=-2)\n",
    "    augmentations.append(('pitch_shift_bajo', ps_audio))\n",
    "    \n",
    "    # Subir volumen\n",
    "    vol_audio = change_volume(audio, factor=1.5)\n",
    "    augmentations.append(('volume_up', vol_audio))\n",
    "\n",
    "    # Bajar volumen\n",
    "    vol_audio = change_volume(audio, factor=0.5)\n",
    "    augmentations.append(('volume_down', vol_audio))\n",
    "    \n",
    "    return augmentations\n",
    "\n",
    "def create_augmented_dataframe(df):\n",
    "    # Crear nuevos audios con los cambios\n",
    "    augmented_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        audio = row['audio']\n",
    "        sr = row['sample_rate']\n",
    "        label = row['label']\n",
    "        base_filepath = row['filepath']\n",
    "        filename = row['filename']\n",
    "        \n",
    "        aug_list = augment_audio(audio, sr)\n",
    "        for aug_method, aug_audio in aug_list:\n",
    "            try:\n",
    "                duration = librosa.get_duration(y=aug_audio, sr=sr)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al calcular duracion {filename} ({aug_method}): {e}\")\n",
    "                duration = None\n",
    "            \n",
    "            augmented_data.append({\n",
    "                'original_filepath': base_filepath,\n",
    "                'filename': filename,\n",
    "                'label': label,\n",
    "                'aug_method': aug_method,\n",
    "                'audio': aug_audio,\n",
    "                'sample_rate': sr,\n",
    "                'duration': duration\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(augmented_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7f9f8-0450-45db-9e81-c1154bb0dd12",
   "metadata": {},
   "source": [
    "Extraccion de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8bcfac-6035-4b21-824f-7466453d6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_audio(audio, sr):\n",
    "    # Extraccion de caracteristicas\n",
    "    \n",
    "    features = {}\n",
    "    features['duration'] = librosa.get_duration(y=audio, sr=sr)\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio)\n",
    "    features['zero_crossing_rate'] = float(np.mean(zcr))\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    spec_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "    features['spectral_centroid'] = float(np.mean(spec_centroid))\n",
    "    \n",
    "    # Spectral Rolloff\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "    features['spectral_rolloff'] = float(np.mean(spec_rolloff))\n",
    "    \n",
    "    # MFCCs (first 13 coefficients)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    for i in range(13):\n",
    "        features[f'mfcc_{i+1}'] = float(np.mean(mfccs[i]))\n",
    "    \n",
    "    # RMS Energy\n",
    "    rms = librosa.feature.rms(y=audio)\n",
    "    features['rms'] = float(np.mean(rms))\n",
    "    \n",
    "    # Tempo (BPM)\n",
    "    try:\n",
    "        tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "        if isinstance(tempo, (list, np.ndarray)):\n",
    "            features['tempo'] = float(tempo[0])\n",
    "        elif isinstance(tempo, str):\n",
    "            features['tempo'] = float(tempo.strip(\"[]\"))\n",
    "        else:\n",
    "            features['tempo'] = float(tempo)\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing tempo: {e}\")\n",
    "        features['tempo'] = None\n",
    "\n",
    "    return features\n",
    "\n",
    "def create_features_from_augmented_dataframe(df_augmented):\n",
    "    \n",
    "    # Crear las caracteristicas para los audios del dataframe\n",
    "    feature_data = []\n",
    "    for idx, row in df_augmented.iterrows():\n",
    "        audio = row['audio']\n",
    "        sr = row['sample_rate']\n",
    "        features = extract_features_from_audio(audio, sr)\n",
    "        \n",
    "        record = {\n",
    "            'original_filepath': row['original_filepath'],\n",
    "            'filename': row['filename'],\n",
    "            'label': row['label'],\n",
    "            'aug_method': row['aug_method']\n",
    "        }\n",
    "        record.update(features)\n",
    "        feature_data.append(record)\n",
    "    \n",
    "    return pd.DataFrame(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1db334f-2b90-4775-bf0f-fd5a93fd5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating Null Audio Files ===\n",
      "Generated: Audios/Audios_Null/null-01_01.wav\n",
      "Generated: Audios/Audios_Null/null-01_02.wav\n",
      "Generated: Audios/Audios_Null/null-01_03.wav\n",
      "Generated: Audios/Audios_Null/null-01_04.wav\n",
      "Generated: Audios/Audios_Null/null-01_05.wav\n",
      "Generated: Audios/Audios_Null/null-02_01.wav\n",
      "Generated: Audios/Audios_Null/null-02_02.wav\n",
      "Generated: Audios/Audios_Null/null-02_03.wav\n",
      "Generated: Audios/Audios_Null/null-02_04.wav\n",
      "Generated: Audios/Audios_Null/null-02_05.wav\n",
      "Generated: Audios/Audios_Null/null-03_01.wav\n",
      "Generated: Audios/Audios_Null/null-03_02.wav\n",
      "Generated: Audios/Audios_Null/null-03_03.wav\n",
      "Generated: Audios/Audios_Null/null-03_04.wav\n",
      "Generated: Audios/Audios_Null/null-03_05.wav\n",
      "\n",
      "=== Loading Audio Files ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/xs2knmd10t5759tsv29bkcv00000gn/T/ipykernel_12221/2975187807.py:14: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_data, sample_rate = librosa.load(filepath, sr=None)\n",
      "/Users/jorgemagdaleno/PycharmProjects/pythonProject/.venv/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "/var/folders/x1/xs2knmd10t5759tsv29bkcv00000gn/T/ipykernel_12221/2975187807.py:14: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_data, sample_rate = librosa.load(filepath, sr=None)\n",
      "/Users/jorgemagdaleno/PycharmProjects/pythonProject/.venv/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Audios DataFrame:\n",
      "                      filepath         filename label  \\\n",
      "0  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis   \n",
      "1  Audios/Luis/LuisG-03_03.m4a  LuisG-03_03.m4a  Luis   \n",
      "2  Audios/Luis/LuisG-01_04.m4a  LuisG-01_04.m4a  Luis   \n",
      "3  Audios/Luis/LuisG-03_01.m4a  LuisG-03_01.m4a  Luis   \n",
      "4  Audios/Luis/LuisG-01_05.m4a  LuisG-01_05.m4a  Luis   \n",
      "\n",
      "                                               audio  sample_rate  duration  \n",
      "0  [-0.00064086914, -0.00036621094, -0.0005493164...        48000  2.281333  \n",
      "1  [-0.0016479492, -0.0016784668, -0.0018615723, ...        48000  2.644000  \n",
      "2  [0.0005187988, 0.00045776367, 0.00033569336, 0...        48000  4.073333  \n",
      "3  [-0.00033569336, -0.00024414062, -0.0004272461...        48000  2.324000  \n",
      "4  [-3.0517578e-05, -0.00064086914, -0.0006713867...        48000  3.156000  \n",
      "\n",
      "=== Creating Augmented Audio Versions ===\n",
      "Augmented Audios DataFrame:\n",
      "             original_filepath         filename label           aug_method  \\\n",
      "0  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis             original   \n",
      "1  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis                noise   \n",
      "2  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis  time_stretch_longer   \n",
      "3  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis  time_stretch_slower   \n",
      "4  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis     pitch_shift_alto   \n",
      "\n",
      "                                               audio  sample_rate  duration  \n",
      "0  [-0.00064086914, -0.00036621094, -0.0005493164...        48000  2.281333  \n",
      "1  [-0.021791279376429128, -0.06062709063940577, ...        48000  2.281333  \n",
      "2  [-0.0006693449, -0.00040139956, -0.0005820912,...        48000  1.901104  \n",
      "3  [-0.0006411603, -0.000367361, -0.0005528169, -...        48000  2.851667  \n",
      "4  [-0.00056019623, -0.00038439786, -0.0006150474...        48000  2.281333  \n",
      "\n",
      "=== Extracting Audio Features ===\n",
      "Extracted Audio Features DataFrame:\n",
      "             original_filepath         filename label           aug_method  \\\n",
      "0  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis             original   \n",
      "1  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis                noise   \n",
      "2  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis  time_stretch_longer   \n",
      "3  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis  time_stretch_slower   \n",
      "4  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis     pitch_shift_alto   \n",
      "\n",
      "   duration  zero_crossing_rate  spectral_centroid  spectral_rolloff  \\\n",
      "0  2.281333            0.050971        3128.588267       6806.512850   \n",
      "1  2.281333            0.383383       10821.715742      19802.935164   \n",
      "2  1.901104            0.053310        3125.840824       7052.199721   \n",
      "3  2.851667            0.052915        3248.202626       7231.168377   \n",
      "4  2.281333            0.059819        3533.907520       7642.486857   \n",
      "\n",
      "       mfcc_1     mfcc_2  ...     mfcc_6    mfcc_7    mfcc_8    mfcc_9  \\\n",
      "0 -470.027588  89.891869  ...  15.687697  4.556073  3.095508  1.611740   \n",
      "1 -183.532831  12.387109  ...   5.928794  2.598976 -0.522675 -0.387177   \n",
      "2 -498.277161  84.537102  ...  15.894697  4.773858  2.262989  1.278148   \n",
      "3 -508.948578  88.553734  ...  14.852035  3.419655  2.133269  0.696415   \n",
      "4 -497.303436  84.401787  ...   9.657138  1.573075  0.197805  3.040892   \n",
      "\n",
      "    mfcc_10   mfcc_11   mfcc_12   mfcc_13       rms       tempo  \n",
      "0  5.337509 -5.140079  2.004782 -1.857108  0.034687  137.195122  \n",
      "1 -0.208196 -1.705091 -1.372827 -1.084688  0.050656   89.285714  \n",
      "2  4.314846 -5.864370  1.201357 -1.775185  0.024946  165.441176  \n",
      "3  5.468492 -4.814297  2.946827 -1.110101  0.021875  110.294118  \n",
      "4  0.265254 -4.452647  2.276324 -1.019287  0.023651  137.195122  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "DataFrames have been saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generar audios nulos\n",
    "print(\"=== Generating Null Audio Files ===\")\n",
    "generate_null_audios(n_files=3, duration=4.0)\n",
    "\n",
    "# Cargar audios\n",
    "print(\"\\n=== Loading Audio Files ===\")\n",
    "df_audios = load_audios_into_dataframe(\"Audios\")\n",
    "print(\"Loaded Audios DataFrame:\")\n",
    "print(df_audios.head())\n",
    "    \n",
    "# Generacion de audios sinteticos\n",
    "print(\"\\n=== Creating Augmented Audio Versions ===\")\n",
    "df_augmented = create_augmented_dataframe(df_audios)\n",
    "print(\"Augmented Audios DataFrame:\")\n",
    "print(df_augmented.head())\n",
    "    \n",
    "# Extraccion de caracteristicas\n",
    "print(\"\\n=== Extracting Audio Features ===\")\n",
    "df_features = create_features_from_augmented_dataframe(df_augmented)\n",
    "print(\"Extracted Audio Features DataFrame:\")\n",
    "print(df_features.head())\n",
    "\n",
    "# Guardar los datos\n",
    "df_audios.to_csv(\"loaded_audios.csv\", index=False)\n",
    "df_augmented.to_csv(\"augmented_audios.csv\", index=False)\n",
    "df_features.to_csv(\"extracted_audio_features.csv\", index=False)\n",
    "print(\"\\nDataFrames have been saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ac0a2-2fae-4fe3-af75-409a226aea99",
   "metadata": {},
   "source": [
    "Tomar archivos y categorizar por quien esta hablando y que frase es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29daf224-6ea8-4a92-83cc-7fb8f54b0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename):\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    try:\n",
    "        name_phrase, recording_id = base.split('_')\n",
    "        name, phrase = name_phrase.split('-')\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Archivo {filename} Formato incorrecto\")\n",
    "    return name, phrase, recording_id\n",
    "\n",
    "def add_metadata_from_filename(df):\n",
    "    speakers, phrases = [], []\n",
    "    for fn in df['filename']:\n",
    "        speaker, phrase, _ = parse_filename(fn)\n",
    "        speakers.append(speaker)\n",
    "        phrases.append(phrase)\n",
    "    df['speaker'] = speakers\n",
    "    df['phrase'] = phrases\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e26b6e-f634-466d-bf7e-4ee0918c1be9",
   "metadata": {},
   "source": [
    "*Algoritmos de categorizacion para el audio.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "257e46dd-c06e-4e73-a04f-3ed1424e97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification ML algorithms\n",
    "lr = LogisticRegression(solver='sag')\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rn_clf = RandomForestClassifier()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "gb = GaussianNB()\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "def trainingModels(x_train, x_test, y_train, y_test):\n",
    "    d = {}\n",
    "    li = [lr, sgd, rn_clf, knn_clf, gb, dt_clf]\n",
    "    models = {}\n",
    "    for i in li:\n",
    "        i.fit(x_train, y_train)\n",
    "        y_pred = i.predict(x_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        model_name = i.__class__.__name__.split('(')[0]\n",
    "        print(model_name, \"accuracy:\", accuracy)\n",
    "        d.update({model_name: accuracy})\n",
    "        models.update({model_name: i})\n",
    "    return d, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f6002-bec7-40b7-b9e7-ad738645251e",
   "metadata": {},
   "source": [
    "*Entrenar modelos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b76d2b93-123e-427e-a52b-e53a39da6041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testeo de 01 ===\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       1.00      0.86      0.92         7\n",
      "           AleM       1.00      1.00      1.00         4\n",
      "  AndresCalzada       1.00      1.00      1.00         8\n",
      "   ArathDaniela       1.00      1.00      1.00        11\n",
      "         Ariana       0.90      1.00      0.95         9\n",
      "          BetoM       0.75      1.00      0.86         6\n",
      "          Bruce       1.00      1.00      1.00         8\n",
      "         Camila       1.00      1.00      1.00         5\n",
      "          Cielo       0.90      1.00      0.95         9\n",
      "         DafneA       1.00      1.00      1.00         8\n",
      "         Daniel       0.88      0.88      0.88        17\n",
      "          David       1.00      0.90      0.95        10\n",
      "         Didier       1.00      1.00      1.00         8\n",
      "            Eri       1.00      0.86      0.92         7\n",
      "           Erik       1.00      0.90      0.95        10\n",
      "       Fernando       0.89      1.00      0.94         8\n",
      "        Ignacio       1.00      0.88      0.93         8\n",
      "           Irma       1.00      1.00      1.00         4\n",
      "           Joan       0.89      1.00      0.94         8\n",
      "          Jorge       1.00      1.00      1.00        10\n",
      "          LuisG       1.00      1.00      1.00         3\n",
      "          Maria       1.00      1.00      1.00         7\n",
      "        Mariana       0.89      1.00      0.94         8\n",
      "          Mario       0.89      1.00      0.94         8\n",
      "         Marlon       0.92      1.00      0.96        12\n",
      "           MauM       1.00      1.00      1.00        10\n",
      "RamosBetancourt       1.00      0.89      0.94         9\n",
      "         Sergio       1.00      1.00      1.00         7\n",
      "        Vanessa       1.00      0.79      0.88        14\n",
      "           null       1.00      1.00      1.00         5\n",
      "\n",
      "       accuracy                           0.96       248\n",
      "      macro avg       0.96      0.96      0.96       248\n",
      "   weighted avg       0.96      0.96      0.96       248\n",
      "\n",
      "=== Testeo de 02 ===\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       1.00      1.00      1.00         8\n",
      "           AleM       1.00      1.00      1.00         7\n",
      "  AndresCalzada       1.00      1.00      1.00         8\n",
      "   ArathDaniela       1.00      1.00      1.00         7\n",
      "         Ariana       1.00      1.00      1.00         8\n",
      "          BetoM       1.00      1.00      1.00         4\n",
      "          Bruce       1.00      1.00      1.00         7\n",
      "         Camila       1.00      1.00      1.00         6\n",
      "          Cielo       0.71      0.71      0.71         7\n",
      "         DafneA       1.00      1.00      1.00        10\n",
      "         Daniel       1.00      1.00      1.00        14\n",
      "          David       1.00      1.00      1.00        10\n",
      "         Didier       1.00      1.00      1.00         5\n",
      "            Eri       1.00      1.00      1.00         8\n",
      "           Erik       1.00      1.00      1.00         8\n",
      "       Fernando       1.00      1.00      1.00        12\n",
      "        Ignacio       1.00      1.00      1.00         7\n",
      "           Irma       1.00      1.00      1.00        11\n",
      "           Joan       1.00      1.00      1.00         8\n",
      "          Jorge       1.00      1.00      1.00         6\n",
      "          LuisG       1.00      1.00      1.00        12\n",
      "          Maria       1.00      1.00      1.00         9\n",
      "        Mariana       1.00      1.00      1.00         8\n",
      "          Mario       1.00      1.00      1.00         7\n",
      "         Marlon       1.00      1.00      1.00         3\n",
      "           MauM       1.00      1.00      1.00         9\n",
      "RamosBetancourt       1.00      1.00      1.00        13\n",
      "         Sergio       1.00      0.93      0.96        14\n",
      "        Vanessa       0.75      0.86      0.80         7\n",
      "           null       1.00      1.00      1.00         5\n",
      "\n",
      "       accuracy                           0.98       248\n",
      "      macro avg       0.98      0.98      0.98       248\n",
      "   weighted avg       0.98      0.98      0.98       248\n",
      "\n",
      "=== Testeo de 03 ===\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       1.00      0.67      0.80         9\n",
      "           AleM       0.83      1.00      0.91         5\n",
      "  AndresCalzada       1.00      1.00      1.00         8\n",
      "   ArathDaniela       1.00      1.00      1.00        11\n",
      "         Ariana       0.82      1.00      0.90         9\n",
      "          BetoM       0.83      1.00      0.91         5\n",
      "          Bruce       1.00      0.75      0.86         8\n",
      "         Camila       1.00      1.00      1.00         5\n",
      "          Cielo       0.82      1.00      0.90         9\n",
      "         DafneA       0.86      1.00      0.92         6\n",
      "         Daniel       0.94      1.00      0.97        16\n",
      "          David       1.00      0.73      0.84        11\n",
      "         Didier       1.00      1.00      1.00         8\n",
      "            Eri       1.00      1.00      1.00         7\n",
      "           Erik       1.00      1.00      1.00         7\n",
      "       Fernando       0.91      1.00      0.95        10\n",
      "        Ignacio       0.83      1.00      0.91        10\n",
      "           Irma       0.80      1.00      0.89         4\n",
      "           Joan       1.00      1.00      1.00         8\n",
      "          Jorge       1.00      1.00      1.00         8\n",
      "          LuisG       0.75      1.00      0.86         3\n",
      "          Maria       0.50      0.57      0.53         7\n",
      "        Mariana       0.79      1.00      0.88        11\n",
      "          Mario       1.00      0.88      0.93         8\n",
      "         Marlon       0.92      0.92      0.92        12\n",
      "           MauM       0.88      0.88      0.88         8\n",
      "RamosBetancourt       0.88      0.78      0.82         9\n",
      "         Sergio       1.00      1.00      1.00         7\n",
      "        Vanessa       1.00      0.50      0.67        14\n",
      "           null       1.00      1.00      1.00         5\n",
      "\n",
      "       accuracy                           0.91       248\n",
      "      macro avg       0.91      0.92      0.91       248\n",
      "   weighted avg       0.92      0.91      0.90       248\n",
      "\n",
      "\n",
      "=== Cross Tests ===\n",
      "\\Modelo entrenado con 01:\n",
      "\n",
      " Prueba con 01:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       1.00      0.97      0.99        40\n",
      "           AleM       1.00      1.00      1.00        40\n",
      "  AndresCalzada       1.00      1.00      1.00        40\n",
      "   ArathDaniela       1.00      1.00      1.00        40\n",
      "         Ariana       0.98      1.00      0.99        40\n",
      "          BetoM       0.95      1.00      0.98        40\n",
      "          Bruce       1.00      1.00      1.00        40\n",
      "         Camila       1.00      1.00      1.00        40\n",
      "          Cielo       0.98      1.00      0.99        40\n",
      "         DafneA       1.00      1.00      1.00        40\n",
      "         Daniel       0.97      0.97      0.97        80\n",
      "          David       1.00      0.97      0.99        40\n",
      "         Didier       1.00      1.00      1.00        40\n",
      "            Eri       1.00      0.97      0.99        40\n",
      "           Erik       1.00      0.97      0.99        40\n",
      "       Fernando       0.98      1.00      0.99        40\n",
      "        Ignacio       1.00      0.97      0.99        40\n",
      "           Irma       1.00      1.00      1.00        40\n",
      "           Joan       0.98      1.00      0.99        40\n",
      "          Jorge       1.00      1.00      1.00        40\n",
      "          LuisG       1.00      1.00      1.00        40\n",
      "          Maria       1.00      1.00      1.00        40\n",
      "        Mariana       0.98      1.00      0.99        40\n",
      "          Mario       0.98      1.00      0.99        40\n",
      "         Marlon       0.98      1.00      0.99        40\n",
      "           MauM       1.00      1.00      1.00        40\n",
      "RamosBetancourt       1.00      0.97      0.99        40\n",
      "         Sergio       1.00      1.00      1.00        40\n",
      "        Vanessa       1.00      0.93      0.96        40\n",
      "           null       1.00      1.00      1.00        40\n",
      "\n",
      "       accuracy                           0.99      1240\n",
      "      macro avg       0.99      0.99      0.99      1240\n",
      "   weighted avg       0.99      0.99      0.99      1240\n",
      "\n",
      "\n",
      " Prueba con 02:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       0.74      0.57      0.65        40\n",
      "           AleM       0.56      0.93      0.70        40\n",
      "  AndresCalzada       0.95      0.53      0.68        40\n",
      "   ArathDaniela       0.77      0.85      0.81        40\n",
      "         Ariana       0.97      0.97      0.97        40\n",
      "          BetoM       0.77      0.82      0.80        40\n",
      "          Bruce       0.97      0.78      0.86        40\n",
      "         Camila       0.83      0.97      0.90        40\n",
      "          Cielo       0.52      0.95      0.67        40\n",
      "         DafneA       0.91      0.75      0.82        40\n",
      "         Daniel       0.89      0.90      0.89        80\n",
      "          David       0.95      0.95      0.95        40\n",
      "         Didier       0.82      0.68      0.74        40\n",
      "            Eri       0.92      0.82      0.87        40\n",
      "           Erik       0.57      0.10      0.17        40\n",
      "       Fernando       0.90      0.90      0.90        40\n",
      "        Ignacio       1.00      0.97      0.99        40\n",
      "           Irma       0.51      0.78      0.61        40\n",
      "           Joan       0.87      0.97      0.92        40\n",
      "          Jorge       0.97      0.85      0.91        40\n",
      "          LuisG       0.84      0.90      0.87        40\n",
      "          Maria       1.00      0.88      0.93        40\n",
      "        Mariana       0.30      0.33      0.31        40\n",
      "          Mario       0.83      0.95      0.88        40\n",
      "         Marlon       0.71      0.80      0.75        40\n",
      "           MauM       0.97      0.90      0.94        40\n",
      "RamosBetancourt       0.55      0.90      0.69        40\n",
      "         Sergio       0.87      0.50      0.63        40\n",
      "        Vanessa       0.64      0.23      0.33        40\n",
      "           null       1.00      1.00      1.00        40\n",
      "\n",
      "       accuracy                           0.78      1240\n",
      "      macro avg       0.80      0.78      0.77      1240\n",
      "   weighted avg       0.81      0.78      0.78      1240\n",
      "\n",
      "\n",
      " Prueba con 03:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       0.47      0.20      0.28        40\n",
      "           AleM       0.42      0.75      0.54        40\n",
      "  AndresCalzada       1.00      0.05      0.10        40\n",
      "   ArathDaniela       0.66      0.72      0.69        40\n",
      "         Ariana       0.73      0.80      0.76        40\n",
      "          BetoM       0.37      0.62      0.47        40\n",
      "          Bruce       0.56      0.45      0.50        40\n",
      "         Camila       0.40      0.85      0.55        40\n",
      "          Cielo       0.70      0.93      0.80        40\n",
      "         DafneA       0.95      0.95      0.95        40\n",
      "         Daniel       0.39      0.79      0.52        80\n",
      "          David       0.91      0.25      0.39        40\n",
      "         Didier       0.90      0.70      0.79        40\n",
      "            Eri       0.86      0.15      0.26        40\n",
      "           Erik       0.26      0.25      0.26        40\n",
      "       Fernando       0.71      1.00      0.83        40\n",
      "        Ignacio       0.93      0.65      0.76        40\n",
      "           Irma       0.57      0.78      0.66        40\n",
      "           Joan       0.82      1.00      0.90        40\n",
      "          Jorge       0.29      0.12      0.18        40\n",
      "          LuisG       0.83      0.60      0.70        40\n",
      "          Maria       0.15      0.05      0.08        40\n",
      "        Mariana       0.31      0.45      0.36        40\n",
      "          Mario       0.59      0.57      0.58        40\n",
      "         Marlon       0.39      0.33      0.36        40\n",
      "           MauM       0.27      0.10      0.15        40\n",
      "RamosBetancourt       0.43      0.68      0.52        40\n",
      "         Sergio       0.74      0.50      0.60        40\n",
      "        Vanessa       0.46      0.15      0.23        40\n",
      "           null       0.95      1.00      0.98        40\n",
      "\n",
      "       accuracy                           0.56      1240\n",
      "      macro avg       0.60      0.55      0.52      1240\n",
      "   weighted avg       0.59      0.56      0.52      1240\n",
      "\n",
      "\\Modelo entrenado con 02:\n",
      "\n",
      " Prueba con 01:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       0.67      0.25      0.36        40\n",
      "           AleM       0.90      0.88      0.89        40\n",
      "  AndresCalzada       0.71      0.85      0.77        40\n",
      "   ArathDaniela       0.67      0.50      0.57        40\n",
      "         Ariana       0.97      0.97      0.97        40\n",
      "          BetoM       0.63      0.97      0.76        40\n",
      "          Bruce       0.97      0.75      0.85        40\n",
      "         Camila       0.89      0.97      0.93        40\n",
      "          Cielo       0.86      0.75      0.80        40\n",
      "         DafneA       0.78      0.97      0.87        40\n",
      "         Daniel       0.61      0.94      0.74        80\n",
      "          David       0.82      0.90      0.86        40\n",
      "         Didier       0.54      0.38      0.44        40\n",
      "            Eri       0.44      0.10      0.16        40\n",
      "           Erik       0.67      0.55      0.60        40\n",
      "       Fernando       0.79      0.95      0.86        40\n",
      "        Ignacio       0.84      0.95      0.89        40\n",
      "           Irma       0.86      0.62      0.72        40\n",
      "           Joan       0.95      0.47      0.63        40\n",
      "          Jorge       0.88      0.55      0.68        40\n",
      "          LuisG       0.84      0.90      0.87        40\n",
      "          Maria       0.47      1.00      0.64        40\n",
      "        Mariana       0.56      0.38      0.45        40\n",
      "          Mario       0.69      1.00      0.82        40\n",
      "         Marlon       0.53      0.40      0.46        40\n",
      "           MauM       0.79      0.93      0.85        40\n",
      "RamosBetancourt       0.66      0.72      0.69        40\n",
      "         Sergio       0.89      0.82      0.86        40\n",
      "        Vanessa       0.55      0.42      0.48        40\n",
      "           null       1.00      1.00      1.00        40\n",
      "\n",
      "       accuracy                           0.74      1240\n",
      "      macro avg       0.75      0.73      0.72      1240\n",
      "   weighted avg       0.74      0.74      0.72      1240\n",
      "\n",
      "\n",
      " Prueba con 02:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       1.00      1.00      1.00        40\n",
      "           AleM       1.00      1.00      1.00        40\n",
      "  AndresCalzada       1.00      1.00      1.00        40\n",
      "   ArathDaniela       1.00      1.00      1.00        40\n",
      "         Ariana       1.00      1.00      1.00        40\n",
      "          BetoM       1.00      1.00      1.00        40\n",
      "          Bruce       1.00      1.00      1.00        40\n",
      "         Camila       1.00      1.00      1.00        40\n",
      "          Cielo       0.95      0.95      0.95        40\n",
      "         DafneA       1.00      1.00      1.00        40\n",
      "         Daniel       1.00      1.00      1.00        80\n",
      "          David       1.00      1.00      1.00        40\n",
      "         Didier       1.00      1.00      1.00        40\n",
      "            Eri       1.00      1.00      1.00        40\n",
      "           Erik       1.00      1.00      1.00        40\n",
      "       Fernando       1.00      1.00      1.00        40\n",
      "        Ignacio       1.00      1.00      1.00        40\n",
      "           Irma       1.00      1.00      1.00        40\n",
      "           Joan       1.00      1.00      1.00        40\n",
      "          Jorge       1.00      1.00      1.00        40\n",
      "          LuisG       1.00      1.00      1.00        40\n",
      "          Maria       1.00      1.00      1.00        40\n",
      "        Mariana       1.00      1.00      1.00        40\n",
      "          Mario       1.00      1.00      1.00        40\n",
      "         Marlon       1.00      1.00      1.00        40\n",
      "           MauM       1.00      1.00      1.00        40\n",
      "RamosBetancourt       1.00      1.00      1.00        40\n",
      "         Sergio       1.00      0.97      0.99        40\n",
      "        Vanessa       0.95      0.97      0.96        40\n",
      "           null       1.00      1.00      1.00        40\n",
      "\n",
      "       accuracy                           1.00      1240\n",
      "      macro avg       1.00      1.00      1.00      1240\n",
      "   weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "\n",
      " Prueba con 03:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       0.00      0.00      0.00        40\n",
      "           AleM       0.48      1.00      0.65        40\n",
      "  AndresCalzada       0.75      0.95      0.84        40\n",
      "   ArathDaniela       0.76      0.80      0.78        40\n",
      "         Ariana       0.75      0.82      0.79        40\n",
      "          BetoM       0.65      0.80      0.72        40\n",
      "          Bruce       0.73      0.68      0.70        40\n",
      "         Camila       0.45      0.70      0.55        40\n",
      "          Cielo       0.67      0.55      0.60        40\n",
      "         DafneA       0.76      0.80      0.78        40\n",
      "         Daniel       0.36      0.91      0.51        80\n",
      "          David       0.20      0.03      0.04        40\n",
      "         Didier       0.32      0.45      0.38        40\n",
      "            Eri       0.33      0.07      0.12        40\n",
      "           Erik       0.52      0.60      0.56        40\n",
      "       Fernando       0.81      0.88      0.84        40\n",
      "        Ignacio       0.89      0.40      0.55        40\n",
      "           Irma       0.50      0.10      0.17        40\n",
      "           Joan       0.71      1.00      0.83        40\n",
      "          Jorge       0.29      0.12      0.18        40\n",
      "          LuisG       0.79      0.38      0.51        40\n",
      "          Maria       0.04      0.03      0.03        40\n",
      "        Mariana       0.00      0.00      0.00        40\n",
      "          Mario       0.61      0.50      0.55        40\n",
      "         Marlon       0.50      0.57      0.53        40\n",
      "           MauM       0.50      0.23      0.31        40\n",
      "RamosBetancourt       0.32      0.15      0.20        40\n",
      "         Sergio       0.81      0.62      0.70        40\n",
      "        Vanessa       0.33      0.40      0.36        40\n",
      "           null       0.95      1.00      0.98        40\n",
      "\n",
      "       accuracy                           0.53      1240\n",
      "      macro avg       0.53      0.52      0.49      1240\n",
      "   weighted avg       0.52      0.53      0.49      1240\n",
      "\n",
      "\\Modelo entrenado con 03:\n",
      "\n",
      " Prueba con 01:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       0.00      0.00      0.00        40\n",
      "           AleM       1.00      0.55      0.71        40\n",
      "  AndresCalzada       0.09      0.03      0.04        40\n",
      "   ArathDaniela       0.39      0.38      0.38        40\n",
      "         Ariana       0.81      0.62      0.70        40\n",
      "          BetoM       0.45      0.93      0.61        40\n",
      "          Bruce       0.80      0.20      0.32        40\n",
      "         Camila       0.64      0.95      0.77        40\n",
      "          Cielo       0.79      0.93      0.85        40\n",
      "         DafneA       0.48      1.00      0.65        40\n",
      "         Daniel       0.74      0.72      0.73        80\n",
      "          David       0.86      0.60      0.71        40\n",
      "         Didier       0.44      1.00      0.62        40\n",
      "            Eri       1.00      0.35      0.52        40\n",
      "           Erik       0.83      0.12      0.22        40\n",
      "       Fernando       0.78      0.88      0.82        40\n",
      "        Ignacio       0.57      1.00      0.73        40\n",
      "           Irma       0.72      0.90      0.80        40\n",
      "           Joan       0.55      0.72      0.62        40\n",
      "          Jorge       1.00      0.30      0.46        40\n",
      "          LuisG       0.59      0.95      0.73        40\n",
      "          Maria       0.00      0.00      0.00        40\n",
      "        Mariana       0.79      0.82      0.80        40\n",
      "          Mario       0.63      0.78      0.70        40\n",
      "         Marlon       0.57      0.57      0.57        40\n",
      "           MauM       0.29      0.38      0.33        40\n",
      "RamosBetancourt       0.54      0.17      0.26        40\n",
      "         Sergio       0.53      0.80      0.64        40\n",
      "        Vanessa       0.00      0.00      0.00        40\n",
      "           null       1.00      1.00      1.00        40\n",
      "\n",
      "       accuracy                           0.59      1240\n",
      "      macro avg       0.60      0.59      0.54      1240\n",
      "   weighted avg       0.60      0.59      0.55      1240\n",
      "\n",
      "\n",
      " Prueba con 02:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       0.11      0.03      0.04        40\n",
      "           AleM       0.90      0.65      0.75        40\n",
      "  AndresCalzada       0.87      0.33      0.47        40\n",
      "   ArathDaniela       0.72      0.65      0.68        40\n",
      "         Ariana       0.88      0.75      0.81        40\n",
      "          BetoM       0.65      1.00      0.78        40\n",
      "          Bruce       0.86      0.62      0.72        40\n",
      "         Camila       0.67      0.93      0.78        40\n",
      "          Cielo       0.32      0.93      0.47        40\n",
      "         DafneA       0.50      0.90      0.64        40\n",
      "         Daniel       0.84      0.72      0.78        80\n",
      "          David       0.80      0.40      0.53        40\n",
      "         Didier       0.20      0.28      0.23        40\n",
      "            Eri       0.80      0.20      0.32        40\n",
      "           Erik       0.79      0.65      0.71        40\n",
      "       Fernando       0.81      0.65      0.72        40\n",
      "        Ignacio       0.56      1.00      0.72        40\n",
      "           Irma       0.46      0.90      0.61        40\n",
      "           Joan       0.85      1.00      0.92        40\n",
      "          Jorge       1.00      0.10      0.18        40\n",
      "          LuisG       0.63      0.47      0.54        40\n",
      "          Maria       0.07      0.07      0.07        40\n",
      "        Mariana       0.40      0.15      0.22        40\n",
      "          Mario       0.96      0.55      0.70        40\n",
      "         Marlon       0.64      0.93      0.76        40\n",
      "           MauM       0.33      0.55      0.42        40\n",
      "RamosBetancourt       0.43      0.23      0.30        40\n",
      "         Sergio       0.48      0.78      0.59        40\n",
      "        Vanessa       0.00      0.00      0.00        40\n",
      "           null       1.00      1.00      1.00        40\n",
      "\n",
      "       accuracy                           0.58      1240\n",
      "      macro avg       0.62      0.58      0.55      1240\n",
      "   weighted avg       0.63      0.58      0.56      1240\n",
      "\n",
      "\n",
      " Prueba con 03:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         AdriaM       1.00      0.93      0.96        40\n",
      "           AleM       0.98      1.00      0.99        40\n",
      "  AndresCalzada       1.00      1.00      1.00        40\n",
      "   ArathDaniela       1.00      1.00      1.00        40\n",
      "         Ariana       0.95      1.00      0.98        40\n",
      "          BetoM       0.98      1.00      0.99        40\n",
      "          Bruce       1.00      0.95      0.97        40\n",
      "         Camila       1.00      1.00      1.00        40\n",
      "          Cielo       0.95      1.00      0.98        40\n",
      "         DafneA       0.98      1.00      0.99        40\n",
      "         Daniel       0.99      1.00      0.99        80\n",
      "          David       1.00      0.93      0.96        40\n",
      "         Didier       1.00      1.00      1.00        40\n",
      "            Eri       1.00      1.00      1.00        40\n",
      "           Erik       1.00      1.00      1.00        40\n",
      "       Fernando       0.98      1.00      0.99        40\n",
      "        Ignacio       0.95      1.00      0.98        40\n",
      "           Irma       0.98      1.00      0.99        40\n",
      "           Joan       1.00      1.00      1.00        40\n",
      "          Jorge       1.00      1.00      1.00        40\n",
      "          LuisG       0.98      1.00      0.99        40\n",
      "          Maria       0.90      0.93      0.91        40\n",
      "        Mariana       0.93      1.00      0.96        40\n",
      "          Mario       1.00      0.97      0.99        40\n",
      "         Marlon       0.97      0.97      0.97        40\n",
      "           MauM       0.97      0.97      0.97        40\n",
      "RamosBetancourt       0.97      0.95      0.96        40\n",
      "         Sergio       1.00      1.00      1.00        40\n",
      "        Vanessa       1.00      0.82      0.90        40\n",
      "           null       1.00      1.00      1.00        40\n",
      "\n",
      "       accuracy                           0.98      1240\n",
      "      macro avg       0.98      0.98      0.98      1240\n",
      "   weighted avg       0.98      0.98      0.98      1240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.read_csv(\"extracted_audio_features.csv\")\n",
    "\n",
    "speakers, phrases = [], []\n",
    "for fn in df_features['filename']:\n",
    "    speaker, phrase, _ = parse_filename(fn)\n",
    "    speakers.append(speaker)\n",
    "    phrases.append(phrase)\n",
    "df_features['speaker'] = speakers\n",
    "df_features['phrase'] = phrases\n",
    "\n",
    "# Seleccionamos las caracteristicas que no dan directamente quien es\n",
    "feature_columns = ['zero_crossing_rate', 'spectral_centroid',\n",
    "                   'spectral_rolloff', 'rms', 'tempo'] + [f'mfcc_{i+1}' for i in range(13)]\n",
    "\n",
    "phrase_models = {}\n",
    "phrase_data = {}\n",
    "\n",
    "for phrase in [\"01\", \"02\", \"03\"]:\n",
    "    df_phrase = df_features[df_features['phrase'] == phrase]\n",
    "    X = df_phrase[feature_columns]\n",
    "    y = df_phrase['speaker']\n",
    "    \n",
    "    # Guardar datos para poder hacer cross testing\n",
    "    phrase_data[phrase] = (X, y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Probando modelos\n",
    "    # m1, models1 = trainingModels(X_train,X_test,y_train,y_test)\n",
    "    # print(m1, models1)\n",
    "    \n",
    "    # Se usa Random forest al ser el que mostro mejor rendimiento\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Testeo con la misma frase\n",
    "    print(f\"=== Testeo de {phrase} ===\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Guardando el modelo para usarlo en live despues\n",
    "    phrase_models[phrase] = clf\n",
    "\n",
    "# Cross test\n",
    "print(\"\\n=== Cross Tests ===\")\n",
    "for train_phrase, model in phrase_models.items():\n",
    "    print(f\"\\Modelo entrenado con {train_phrase}:\")\n",
    "    for test_phrase, (X_test, y_test) in phrase_data.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"\\n Prueba con {test_phrase}:\")\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167b52b-a615-4fd0-96f2-810e3b5df4fb",
   "metadata": {},
   "source": [
    "*Prueba en vivo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cab8420-cabc-4fb6-82ab-9f06914b3d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for phrase 01 exported to model_phrase_01.pkl\n",
      "Model for phrase 02 exported to model_phrase_02.pkl\n",
      "Model for phrase 03 exported to model_phrase_03.pkl\n"
     ]
    }
   ],
   "source": [
    "# Exportamos los modelos creados\n",
    "for phrase, model in phrase_models.items():\n",
    "    filename = f\"model_phrase_{phrase}.pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Model for phrase {phrase} exported to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e58724d4-41a0-4356-b9b2-fdfe1cec75a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Habla al microfono...\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Bruce\n",
      "Predicted Speaker 2: Bruce\n",
      "Predicted Speaker 3: Bruce\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Daniel\n",
      "Predicted Speaker 2: Daniel\n",
      "Predicted Speaker 3: Daniel\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Daniel\n",
      "Predicted Speaker 2: Daniel\n",
      "Predicted Speaker 3: Daniel\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Cielo\n",
      "Predicted Speaker 2: Cielo\n",
      "Predicted Speaker 3: Cielo\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Daniel\n",
      "Predicted Speaker 2: Daniel\n",
      "Predicted Speaker 3: Daniel\n",
      "Grabando por 4 segundos...\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Grabando por 4 segundos...\n",
      "Detenido.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import joblib\n",
    "\n",
    "# Grabar Voz\n",
    "def record_audio(duration=4, sample_rate=44100):\n",
    "    print(f\"Grabando por {duration} segundos...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()\n",
    "    return np.squeeze(audio), sample_rate\n",
    "\n",
    "# Cargar modelo\n",
    "def load_model(model_filename):\n",
    "    return joblib.load(model_filename)\n",
    "\n",
    "# Hacer prediccion\n",
    "def predict_speaker(model, feature_vector):\n",
    "    prediction = model.predict(feature_vector)\n",
    "    return prediction[0]\n",
    "\n",
    "# Loop\n",
    "def main_inference_loop():\n",
    "    # Cargar modelos \n",
    "    model_1 = load_model(\"model_phrase_01.pkl\")\n",
    "    model_2 = load_model(\"model_phrase_02.pkl\")\n",
    "    model_3 = load_model(\"model_phrase_03.pkl\")\n",
    "    \n",
    "    print(\"Habla al microfono...\")\n",
    "    try:\n",
    "        while True:\n",
    "            # Grabar audio\n",
    "            audio, sr = record_audio()\n",
    "            \n",
    "            # Tomar caracteristicas de grabacion\n",
    "            features = extract_features_from_audio(audio, sr)\n",
    "            \n",
    "            # Obtener vectores\n",
    "            feature_vector = pd.DataFrame([features], columns=feature_columns)\n",
    "            \n",
    "            # Predicciones\n",
    "            predicted_speaker_1 = predict_speaker(model_1, feature_vector)\n",
    "            predicted_speaker_2 = predict_speaker(model_2, feature_vector)\n",
    "            predicted_speaker_3 = predict_speaker(model_3, feature_vector)\n",
    "            print(\"Predicted Speaker 1:\", predicted_speaker_1)\n",
    "            print(\"Predicted Speaker 2:\", predicted_speaker_1)\n",
    "            print(\"Predicted Speaker 3:\", predicted_speaker_1)\n",
    "            \n",
    "            # Pausa\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Detenido.\")\n",
    "\n",
    "# Llamar al loop\n",
    "if __name__ == \"__main__\":\n",
    "    main_inference_loop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
